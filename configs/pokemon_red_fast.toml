# NeuralQuest Fast Training Configuration for Pokemon Red
# Accelerated learning with higher exploration for faster progress

[env]
frame_skip = 6          # Higher frame skip for faster training
sticky_p = 0.02         # Very low sticky for rapid exploration
seed = 1337
max_episode_steps = 25000  # Shorter episodes for faster iteration
deterministic = true

[algo]
gamma = 0.995           # Standard discount
gae_lambda = 0.95       # Standard GAE
lr_policy = 5e-4        # Higher learning rate for faster learning
lr_value = 5e-4
batch_horizon = 2048    # Standard batch size
entropy_coeff = 0.05    # Much higher entropy for aggressive exploration
value_coeff = 0.5
grad_clip = 5.0
epochs_per_update = 2   # Fewer epochs for faster updates
minibatch_size = 256

[rnd]
beta = 0.3              # Higher intrinsic motivation for rapid exploration
lr = 2e-3               # Higher RND learning rate
reward_clip = 5.0       # Standard clipping
norm_ema = 0.98         # Faster adaptation
hidden_dim = 128        # Standard size for speed

[archive]
hash_bits = 64
capacity = 50000        # Smaller archive for faster management
p_frontier = 0.4        # Much higher frontier sampling for exploration
novel_lru = 5000        # Smaller LRU window
evict_on = "old_and_often"
hamming_threshold = 2   # Lower threshold for more novelty detection
projection_dim = 64     # Smaller projection for speed

[train]
epochs = 20000          # Shorter training period
ckpt_every = 200        # Frequent checkpoints
log_every = 20          # Frequent logging for monitoring
eval_every = 1000       # Regular evaluation
save_dir = "pokemon_fast_checkpoints"
log_dir = "pokemon_fast_logs"