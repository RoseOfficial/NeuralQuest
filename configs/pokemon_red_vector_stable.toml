# NeuralQuest Configuration for Pokemon Red - STABILITY IMPROVED
# Fixed learning rates, gradient clipping, and value function stability

[env]
frame_skip = 4          # Standard frame skip for RPG pacing
sticky_p = 0.1          # Higher sticky for more persistent actions
seed = 1337             # Reproducible seed
max_episode_steps = 2000 # Shorter episodes to reduce memory pressure
deterministic = true    # Enable deterministic execution
headless = true         # Default headless (overridden by visual_env_idx)
use_progress_detector = false  # Disable progress detector for maximum performance

[algo]
gamma = 0.995           # Slightly lower discount to focus on shorter-term exploration
gae_lambda = 0.95       # Standard GAE lambda
lr_policy = 3e-5        # REDUCED: Lower learning rate for stability after epoch 30+
lr_value = 5e-5         # REDUCED: Slightly higher than policy to stabilize value function
batch_horizon = 2048    # OPTIMAL: Fast updates while maintaining stability
entropy_coeff = 0.05    # Moderate entropy to prevent premature convergence
value_coeff = 1.0       # INCREASED: Higher value coefficient for stability
grad_clip = 0.5         # REDUCED: Tighter gradient clipping to prevent spikes
epochs_per_update = 2   # Fewer epochs per update to reduce memory
minibatch_size = 512    # Smaller minibatches for memory efficiency

[rnd]
beta = 0.1              # REDUCED: Lower intrinsic reward to reduce value instability
lr = 2e-5               # REDUCED: Lower RND learning rate for stability
reward_clip = 3.0       # REDUCED: Tighter reward clipping
norm_ema = 0.999        # Slower normalization to prevent variance collapse
hidden_dim = 256        # Standard RND network size

[archive]
hash_bits = 64          # Full 64-bit hashing
capacity = 500000       # Large archive for comprehensive exploration
p_frontier = 0.6        # High frontier probability for exploration
novel_lru = 50000       # Large LRU window for novelty detection
evict_on = "old_and_often"  # Intelligent eviction strategy
hamming_threshold = 2   # Fine-grained novelty detection
projection_dim = 64     # Efficient projection dimension

[train]
epochs = 10000          # Long training for comprehensive learning
ckpt_every = 1          # Save every epoch for progress tracking
log_every = 5           # More frequent logging for better monitoring
eval_every = 50         # Regular evaluation for performance tracking
save_dir = "pokemon_vector_checkpoints_stable"
log_dir = "pokemon_vector_logs_stable"
n_envs = 10             # 10 parallel PyBoy instances
visual_env_idx = -1     # All headless for maximum performance